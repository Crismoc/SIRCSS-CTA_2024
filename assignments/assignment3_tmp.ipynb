{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MansMeg/IntroML/blob/master/assignments/swedish_bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUi3l-lEOpD"
      },
      "source": [
        "# Classification of motions from the Swedish Parliament (Riksdagen) using a Swedish BERT model\n",
        "\n",
        "Here we demonstrate how to perform document classification using models from the `transformers` Python library. We will be using a dataset consisting of parliamentary motions from the Swedish Parliament (Riksdagen). Can we predict which party authored a parliamentary motion using only the text of a motion as input?\n",
        "\n",
        "Huggingface `transformers` library has many high level abstractions for making training of large language models \"simpler\". In particular there is the `Trainer` class for launching training, and the `datasets` library for loading and working with Huggingface datasets. There are already [plenty](https://huggingface.co/course/chapter3/3?fw=pt) of guides on the internet showing [how to use these tools](https://huggingface.co/transformers/v3.2.0/custom_datasets.html#fine-tuning-with-trainer).\n",
        "\n",
        "While these high level abstractions might help make tutorials more succinct and straight to the point, it usually comes at the cost of creating barriers for students and practicians who at some later point may need to adapt their use to custom datasets and (non-standard) training objectives.\n",
        "\n",
        "The patterns used in this guide will therefore all be standard Pytorch abstractions for creating datasets, dataloaders and writing your own custom training loops for transformer model trained for Swedish. These patterns are general for Pytorch, and thus applicable in almost all situations where you're working with Pytorch models. Your capacity to customize and change things is only limited by your knowledge of Pytorch and your basic coding abilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueKXhHifhKRI"
      },
      "source": [
        "## Setting up data\n",
        "\n",
        "### Installing the `transformers` library\n",
        "\n",
        "Google Colab has the `transformers` library already installed. Should this not be the case for you, run the cell below.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRpTgvv0hX5r",
        "outputId": "81fb5ba6-4439-45be-e798-907fb0f00402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2C6ES5LFq-M"
      },
      "source": [
        "### Downloading the Swedish parliamentary corpus\n",
        "\n",
        "We download a dataset of parliamentary motions from the years 2014-2021 that has been collected from the Swedish parliament open data and prepared in advance. The interested reader can see where the data was [downloaded from](https://github.com/kb-labb/bertopic_workshop/blob/main/download_data.sh) and how it was [preprocessed](https://github.com/kb-labb/bertopic_workshop/blob/main/parse_motioner.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_28mJ1GWCB4Y",
        "outputId": "6764db13-ed42-445c-ad64-34bfd0528f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100     8    0     8    0     0      6      0 --:--:--  0:00:01 --:--:--  8000\n",
            "100 90.6M  100 90.6M    0     0  10.1M      0  0:00:08  0:00:08 --:--:-- 17.5M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://kungliga-biblioteket.box.com/shared/static/ii4yhmj0f5do0ifjtj1nzb13iy7dkq5e --output motioner_2014_2021.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePb4_9EvHkUw"
      },
      "source": [
        "We read our data file `motioner_2014_2021.parquet` as a dataframe and display a table of it below.\n",
        "\n",
        "Here's a brief explanation of some column variables whose names may not be fully self-explanatory:\n",
        "\n",
        "* **doc_id**: Unique id that identifies each parliamentary motion document.\n",
        "* **text**: Contains the full body text of the parliamentary motion (truncated in the table below).\n",
        "* **datum**: Date.\n",
        "* **dokument_html_url**: An URL to the document in html-format on Riksdagen's website.\n",
        "* **titel**: Title.\n",
        "* **subtitel**: Who wrote the motion (\"m.fl.\" can be translated \"et al.\").\n",
        "* **organ**: Abbreviations of the different [committees (\"utskott\")](https://sv.wikipedia.org/wiki/Riksdagsutskott_(Sverige)) of the riksdag.  \n",
        "* **subtyp**: Type of motion. Whether it was submitted by an individual member (Enskild motion), a committee (Kommitt√©motion), a political party (partimotion), or several parties (flerpartimotion).\n",
        "* **authors_\\***: How many authors from each individual party that wrote the motion.\n",
        "* **nr_authors**: Total number of listed authors.\n",
        "* **party**: Party abbreviations of party/parties involved in writing the motion, separated by commas.\n",
        "* **single_party_authors**: Boolean variable indicating whether the authors of the motion were all from the same party (True), or whether it was a collaboration between several parties (False).\n",
        "\n",
        "We use the `pandas` library to read in the corpus and display the five first motions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "Quc3yyagHNCc",
        "outputId": "0f81ae9b-e48b-4005-ac4f-e12edc6ea828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset consists of a total of 29851 motions.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dc11b082-75db-4d0b-a47e-e607474cecb2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dok_id</th>\n",
              "      <th>text</th>\n",
              "      <th>datum</th>\n",
              "      <th>dokument_url_html</th>\n",
              "      <th>titel</th>\n",
              "      <th>subtitel</th>\n",
              "      <th>organ</th>\n",
              "      <th>subtyp</th>\n",
              "      <th>hangar_id</th>\n",
              "      <th>authors_V</th>\n",
              "      <th>...</th>\n",
              "      <th>authors_MP</th>\n",
              "      <th>authors_C</th>\n",
              "      <th>authors_L</th>\n",
              "      <th>authors_KD</th>\n",
              "      <th>authors_M</th>\n",
              "      <th>authors_SD</th>\n",
              "      <th>authors_independent</th>\n",
              "      <th>nr_authors</th>\n",
              "      <th>party</th>\n",
              "      <th>single_party_authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>H9023691</td>\n",
              "      <td>Den svenska gruv- och mineraln√§ringen var med ...</td>\n",
              "      <td>2021-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H9023691</td>\n",
              "      <td>En konkurrenskraftig gruvn√§ring f√∂r framtiden</td>\n",
              "      <td>av Lars Hj√§lmered m.fl. (M)</td>\n",
              "      <td>NU</td>\n",
              "      <td>Kommitt√©motion</td>\n",
              "      <td>5109435</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H6022337</td>\n",
              "      <td>Regeringen beslutade under 2017 att anta en na...</td>\n",
              "      <td>2018-11-29</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H6022337</td>\n",
              "      <td>Starkare nationell cykelpolitik</td>\n",
              "      <td>av Emma Berginger (MP)</td>\n",
              "      <td>TU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>5012022</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>MP</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>H8023930</td>\n",
              "      <td>Regeringen f√∂resl√•r genom proposition 2020/21:...</td>\n",
              "      <td>2021-04-07</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H8023930</td>\n",
              "      <td>med anledning av prop. 2020/21:159 Vissa ident...</td>\n",
              "      <td>av Christina H√∂j Larsen m.fl. (V)</td>\n",
              "      <td>SfU</td>\n",
              "      <td>Kommitt√©motion</td>\n",
              "      <td>5092870</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>V</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>H80268</td>\n",
              "      <td>Under en sommarkv√§ll 2018 misshandlades en per...</td>\n",
              "      <td>2020-09-11</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H80268</td>\n",
              "      <td>Utvidgad n√∂dv√§rnsr√§tt</td>\n",
              "      <td>av Markus Wiechel och Alexander Christiansson ...</td>\n",
              "      <td>JuU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>5066863</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H3021446</td>\n",
              "      <td>F√∂retag skapar arbetstillf√§llen och bidrar til...</td>\n",
              "      <td>2015-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H3021446</td>\n",
              "      <td>F√∂retagsdag p√• h√∂gstadiet och gymnasiet</td>\n",
              "      <td>av Johan Nissinen (SD)</td>\n",
              "      <td>UbU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4386670</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29846</th>\n",
              "      <td>H9021195</td>\n",
              "      <td>F√§rjetrafiken till Gotland √§r √∂ns landsv√§g, de...</td>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H9021195</td>\n",
              "      <td>Statligt ansvar f√∂r en reservhamn i Gotlandstr...</td>\n",
              "      <td>av Lars Thomsson (C)</td>\n",
              "      <td>TU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>5106758</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29847</th>\n",
              "      <td>H5023547</td>\n",
              "      <td>L√§nge har problemet just varit att Sverige int...</td>\n",
              "      <td>2017-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H5023547</td>\n",
              "      <td>Visum och bidragssanktioner mot l√§nder som int...</td>\n",
              "      <td>av Kent Ekeroth (SD)</td>\n",
              "      <td>SfU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4773394</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29848</th>\n",
              "      <td>H2021061</td>\n",
              "      <td>Inf√∂r riksdagsvalen g√•r debattens v√•gor h√∂ga. ...</td>\n",
              "      <td>2014-11-07</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H2021061</td>\n",
              "      <td>F√∂rb√§ttrad kvalitet i valdebatten</td>\n",
              "      <td>av Betty Malmberg (M)</td>\n",
              "      <td>KU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>3111220</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29849</th>\n",
              "      <td>H5023948</td>\n",
              "      <td>Riksrevisionen riktar mycket allvarlig kritik ...</td>\n",
              "      <td>2018-01-09</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H5023948</td>\n",
              "      <td>med anledning av skr. 2017/18:68 Riksrevisione...</td>\n",
              "      <td>av Stefan Jakobsson och Robert Stenkvist (b√•da...</td>\n",
              "      <td>UbU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4785744</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29850</th>\n",
              "      <td>H3021050</td>\n",
              "      <td>Delningsekonomin, som inneb√§r att vi delar all...</td>\n",
              "      <td>2015-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H3021050</td>\n",
              "      <td>Delningsekonomi</td>\n",
              "      <td>av Jessica Rosencrantz (M)</td>\n",
              "      <td>NU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4386185</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29851 rows √ó 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc11b082-75db-4d0b-a47e-e607474cecb2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc11b082-75db-4d0b-a47e-e607474cecb2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc11b082-75db-4d0b-a47e-e607474cecb2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-639c49d6-2a2b-45a6-8b38-e780f566c821\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-639c49d6-2a2b-45a6-8b38-e780f566c821')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-639c49d6-2a2b-45a6-8b38-e780f566c821 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         dok_id                                               text      datum  \\\n",
              "0      H9023691  Den svenska gruv- och mineraln√§ringen var med ... 2021-10-05   \n",
              "1      H6022337  Regeringen beslutade under 2017 att anta en na... 2018-11-29   \n",
              "2      H8023930  Regeringen f√∂resl√•r genom proposition 2020/21:... 2021-04-07   \n",
              "3        H80268  Under en sommarkv√§ll 2018 misshandlades en per... 2020-09-11   \n",
              "4      H3021446  F√∂retag skapar arbetstillf√§llen och bidrar til... 2015-10-05   \n",
              "...         ...                                                ...        ...   \n",
              "29846  H9021195  F√§rjetrafiken till Gotland √§r √∂ns landsv√§g, de... 2021-09-30   \n",
              "29847  H5023547  L√§nge har problemet just varit att Sverige int... 2017-10-05   \n",
              "29848  H2021061  Inf√∂r riksdagsvalen g√•r debattens v√•gor h√∂ga. ... 2014-11-07   \n",
              "29849  H5023948  Riksrevisionen riktar mycket allvarlig kritik ... 2018-01-09   \n",
              "29850  H3021050  Delningsekonomin, som inneb√§r att vi delar all... 2015-10-05   \n",
              "\n",
              "                                dokument_url_html  \\\n",
              "0      http://data.riksdagen.se/dokument/H9023691   \n",
              "1      http://data.riksdagen.se/dokument/H6022337   \n",
              "2      http://data.riksdagen.se/dokument/H8023930   \n",
              "3        http://data.riksdagen.se/dokument/H80268   \n",
              "4      http://data.riksdagen.se/dokument/H3021446   \n",
              "...                                           ...   \n",
              "29846  http://data.riksdagen.se/dokument/H9021195   \n",
              "29847  http://data.riksdagen.se/dokument/H5023547   \n",
              "29848  http://data.riksdagen.se/dokument/H2021061   \n",
              "29849  http://data.riksdagen.se/dokument/H5023948   \n",
              "29850  http://data.riksdagen.se/dokument/H3021050   \n",
              "\n",
              "                                                   titel  \\\n",
              "0          En konkurrenskraftig gruvn√§ring f√∂r framtiden   \n",
              "1                        Starkare nationell cykelpolitik   \n",
              "2      med anledning av prop. 2020/21:159 Vissa ident...   \n",
              "3                                  Utvidgad n√∂dv√§rnsr√§tt   \n",
              "4                F√∂retagsdag p√• h√∂gstadiet och gymnasiet   \n",
              "...                                                  ...   \n",
              "29846  Statligt ansvar f√∂r en reservhamn i Gotlandstr...   \n",
              "29847  Visum och bidragssanktioner mot l√§nder som int...   \n",
              "29848                  F√∂rb√§ttrad kvalitet i valdebatten   \n",
              "29849  med anledning av skr. 2017/18:68 Riksrevisione...   \n",
              "29850                                    Delningsekonomi   \n",
              "\n",
              "                                                subtitel organ  \\\n",
              "0                            av Lars Hj√§lmered m.fl. (M)    NU   \n",
              "1                                 av Emma Berginger (MP)    TU   \n",
              "2                      av Christina H√∂j Larsen m.fl. (V)   SfU   \n",
              "3      av Markus Wiechel och Alexander Christiansson ...   JuU   \n",
              "4                                 av Johan Nissinen (SD)   UbU   \n",
              "...                                                  ...   ...   \n",
              "29846                               av Lars Thomsson (C)    TU   \n",
              "29847                               av Kent Ekeroth (SD)   SfU   \n",
              "29848                              av Betty Malmberg (M)    KU   \n",
              "29849  av Stefan Jakobsson och Robert Stenkvist (b√•da...   UbU   \n",
              "29850                         av Jessica Rosencrantz (M)    NU   \n",
              "\n",
              "               subtyp  hangar_id  authors_V  ...  authors_MP  authors_C  \\\n",
              "0      Kommitt√©motion    5109435          0  ...           0          0   \n",
              "1      Enskild motion    5012022          0  ...           1          0   \n",
              "2      Kommitt√©motion    5092870          5  ...           0          0   \n",
              "3      Enskild motion    5066863          0  ...           0          0   \n",
              "4      Enskild motion    4386670          0  ...           0          0   \n",
              "...               ...        ...        ...  ...         ...        ...   \n",
              "29846  Enskild motion    5106758          0  ...           0          1   \n",
              "29847  Enskild motion    4773394          0  ...           0          0   \n",
              "29848  Enskild motion    3111220          0  ...           0          0   \n",
              "29849  Enskild motion    4785744          0  ...           0          0   \n",
              "29850  Enskild motion    4386185          0  ...           0          0   \n",
              "\n",
              "       authors_L  authors_KD  authors_M  authors_SD  authors_independent  \\\n",
              "0              0           0          4           0                    0   \n",
              "1              0           0          0           0                    0   \n",
              "2              0           0          0           0                    0   \n",
              "3              0           0          0           2                    0   \n",
              "4              0           0          0           1                    0   \n",
              "...          ...         ...        ...         ...                  ...   \n",
              "29846          0           0          0           0                    0   \n",
              "29847          0           0          0           1                    0   \n",
              "29848          0           0          1           0                    0   \n",
              "29849          0           0          0           2                    0   \n",
              "29850          0           0          1           0                    0   \n",
              "\n",
              "       nr_authors  party single_party_authors  \n",
              "0               4      M                 True  \n",
              "1               1     MP                 True  \n",
              "2               5      V                 True  \n",
              "3               2     SD                 True  \n",
              "4               1     SD                 True  \n",
              "...           ...    ...                  ...  \n",
              "29846           1      C                 True  \n",
              "29847           1     SD                 True  \n",
              "29848           1      M                 True  \n",
              "29849           2     SD                 True  \n",
              "29850           1      M                 True  \n",
              "\n",
              "[29851 rows x 21 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet(\"motioner_2014_2021.parquet\")\n",
        "print(f\"The dataset consists of a total of {len(df)} motions.\")\n",
        "df # Display only the 5 first rows of the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUpynRhUIwyd"
      },
      "source": [
        "### Prepare the corpus\n",
        "\n",
        "Before we can get started, we first need to\n",
        "\n",
        "1. create an integer label column we want to classify.\n",
        "2. divide our data into a training and evaluation set.\n",
        "\n",
        "A small proportion of parliamentary motions are also the result of several members of parliament collaborating across party lines. In this guide, we make it simple for ourselves and simply filter out the observations with multiple authors from different political parties.\n",
        "\n",
        "For now, we include only 'enskilda motioner' below.\n",
        "\n",
        "Training can take upwards to 2-3 hours if we include all observations. For this reason we select a subset of the data spanning the last mandate period from 2018-10-01 and forwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "RLaUGkjsH5FC",
        "outputId": "efa2a60c-07fc-47ce-d6bc-4919992a3af3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train[[\\\"dok_id\\\", \\\"text\\\", \\\"party\\\", \\\"label\\\", \\\"titel\\\", \\\"subtitel\\\"]]\",\n  \"rows\": 19858,\n  \"fields\": [\n    {\n      \"column\": \"dok_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19858,\n        \"samples\": [\n          \"H6021548\",\n          \"H3022068\",\n          \"H8022789\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18396,\n        \"samples\": [\n          \"Vi st\\u00e5r inf\\u00f6r utmaningar inom kompetensomr\\u00e5det samh\\u00e4llsbyggare. Bristen p\\u00e5 kompetens inom infrastruktursektorn har \\u00f6kat under senare \\u00e5r inom s\\u00e5v\\u00e4l h\\u00f6gskoleyrken som andra yrken inom branschen. Detta samtidigt som vi ser en utveckling i regionen med kraftig utbyggnad, viktiga infrastruktursatsningar och m\\u00e5nga nya bost\\u00e4der. F\\u00f6r att kunna m\\u00f6ta den efterfr\\u00e5gan som finns fr\\u00e5n s\\u00e5v\\u00e4l kommuner och regioner som fr\\u00e5n statliga projekt m\\u00e5ste krafttag till f\\u00f6r att inte f\\u00f6rlora i utvecklingspotential. Det r\\u00e5der brist p\\u00e5 arbetskraft i branschen hela v\\u00e4gen fr\\u00e5n planering via projektering till utf\\u00f6rande, vilket beh\\u00f6ver \\u00e5tg\\u00e4rdas f\\u00f6r att klara behoven inom infrastruktursektorn. F\\u00f6r att svara upp mot Stockholm-M\\u00e4lardalsregionens behov av nya v\\u00e4gar, hamnar och j\\u00e4rnv\\u00e4gar beh\\u00f6ver kompetensf\\u00f6rs\\u00f6rjningen inkluderas i b\\u00e5de planeringen av infrastruktur och utbildningar. Tidigare studier som tagits fram bland annat av M\\u00e4lardalsr\\u00e5det har visat att utbildningar inom bristyrken beh\\u00f6ver erbjudas regionalt, n\\u00e4ra bristmarknaden, f\\u00f6r att s\\u00e4kra den regionala kompetensf\\u00f6rs\\u00f6rjningen. F\\u00f6r att l\\u00f6sa kompetensbristen och s\\u00e4kra regionen som tillv\\u00e4xtmotor och en viktig framtida nod i norra Europa beh\\u00f6vs en f\\u00f6rb\\u00e4ttrad m\\u00f6jlighet till samh\\u00e4llsbyggnadsutbildningar i Stockholm-M\\u00e4lardalsregionen.\",\n          \"I en globaliserad v\\u00e4rld m\\u00e5ste erfarenhet och utbyten ske, inte minst inom universiteten och h\\u00f6gskolorna. F\\u00f6r att Sverige ska beh\\u00e5lla sin status som kunskapsnation m\\u00e5ste vi b\\u00e5de attrahera och beh\\u00e5lla utl\\u00e4ndska talanger s\\u00e5som doktorander och g\\u00e4stforskare fr\\u00e5n l\\u00e4nder utanf\\u00f6r EU och EES. F\\u00f6r att dessa ska v\\u00e4lja Sverige i h\\u00f6gre utstr\\u00e4ckning b\\u00f6r handl\\u00e4ggningstiden f\\u00f6r uppeh\\u00e5llstillst\\u00e5nd ses \\u00f6ver och regelf\\u00f6renklingar genomf\\u00f6ras. Tidigare har uppeh\\u00e5llstillst\\u00e5nd f\\u00f6r doktorander som kommer fr\\u00e5n utanf\\u00f6r EU och ESS beviljats p\\u00e5 ett\\u00e5rsbasis. Migrationsverket har efter dialog med l\\u00e4ros\\u00e4ten \\u00e4ndrat regelverket s\\u00e5 att doktorander och g\\u00e4stforskare fr\\u00e5n l\\u00e4nder utanf\\u00f6r EU och EES beviljas uppeh\\u00e5llstillst\\u00e5nd om tv\\u00e5 \\u00e5r ist\\u00e4llet f\\u00f6r ett \\u00e5r, vilket \\u00e4r positivt. Oml\\u00e4ggningen till tv\\u00e5 \\u00e5r har dock inneburit en f\\u00f6rl\\u00e4ngning av hanteringstiden f\\u00f6r \\u00e4renden som r\\u00f6r uppeh\\u00e5llstillst\\u00e5nd. Med erfarenhet fr\\u00e5n tidigare handl\\u00e4ggningstid inom Migrationsverket b\\u00f6r det g\\u00e5 att f\\u00f6renkla och d\\u00e4rmed f\\u00f6rkorta Migrationsverkets handl\\u00e4ggningstider. Nuvarande l\\u00e5nga handl\\u00e4ggningstid skapar os\\u00e4kerhet och oro samtidigt som sv\\u00e5righeter uppst\\u00e5r avseende de r\\u00e4ttigheter och sociala f\\u00f6rm\\u00e5ner som g\\u00e4ller i v\\u00e4ntan p\\u00e5 nytt uppeh\\u00e5llstillst\\u00e5nd. Som exempel kan n\\u00e4mnas ett fall d\\u00e4r en doktorand nekades f\\u00f6r\\u00e4ldrapenning fr\\u00e5n F\\u00f6rs\\u00e4kringskassan p\\u00e5 grund av en l\\u00e5ng handl\\u00e4ggningstid hos Migrationsverket samt p\\u00e5 grund av otydligheter hos F\\u00f6rs\\u00e4kringskassan. Doktoranden som f\\u00f6rst nekades ers\\u00e4ttning beg\\u00e4rde sedan ompr\\u00f6vning av beslutet och fick r\\u00e4tt. Den h\\u00e4r typen av problematik p\\u00e5verkar Sveriges st\\u00e4llning som en avancerad kunskapsnation negativt genom att det bidrar till att g\\u00f6ra det mindre attraktivt att f\\u00f6rl\\u00e4gga doktorandstudier och forskarinsatser till Sverige. I en globaliserad v\\u00e4rld \\u00e4r konkurrensen som allra tuffast om h\\u00f6gspecialiserad kompetens och ska Sverige forts\\u00e4tta vara en ledande v\\u00e4lf\\u00e4rdsnation f\\u00e5r vi inte tappa attraktionskraften till svenska universitet och h\\u00f6gskolor. Ist\\u00e4llet ska vi locka och beh\\u00e5lla kompetenta studenter och forskare. Handl\\u00e4ggningstiderna hos Migrationsverket f\\u00f6r utl\\u00e4ndska doktorander och g\\u00e4stforskare och deras medf\\u00f6ljande b\\u00f6r d\\u00e4rf\\u00f6r prioriteras. Regeringen b\\u00f6r d\\u00e4rf\\u00f6r se \\u00f6ver huruvida det \\u00e4r m\\u00f6jligt att skapa en s\\u00e4rskild och f\\u00f6renklad hanteringsordning p\\u00e5 Migrationsverket f\\u00f6r ans\\u00f6kningar om uppeh\\u00e5llstillst\\u00e5nd fr\\u00e5n utl\\u00e4ndska doktorander och g\\u00e4stforskare s\\u00e5 att dessa kan granskas skyndsamt.\",\n          \"Regeringen har som m\\u00e5l att genomf\\u00f6ra allt fler utvisningar. Det \\u00e4r positivt att regeringen \\u00e4mnar uppr\\u00e4tth\\u00e5lla lagar och regler men d\\u00e5 m\\u00e5ste polisen ocks\\u00e5 f\\u00e5 erforderliga resurser f\\u00f6r att kunna f\\u00f6lja regeringens beslut. I Norrland \\u00e4r gr\\u00e4nspolisens situation n\\u00e4rmast oh\\u00e5llbar p\\u00e5 grund av att Migrationsverkets enda f\\u00f6rvar finns i G\\u00e4vle. I praktiken kan det inneb\\u00e4ra att en enskild polispatrull kan beh\\u00f6va k\\u00f6ra fram och tillbaka mellan exempelvis Kiruna och G\\u00e4vle, \\u00f6ver 200 mil, bara f\\u00f6r att l\\u00e4mna n\\u00e5gon p\\u00e5 f\\u00f6rvaret. I l\\u00e4ngden \\u00e4r inte detta ett effektivt nyttjande av polisens resurser i ett l\\u00e4ge d\\u00e4r organisationen \\u00e4r anstr\\u00e4ngd. Situationen \\u00e4r oh\\u00e5llbar och poliser vittnar om att de tvingats sl\\u00e4ppa personer som ertappats i rutinkontroller. Regeringen b\\u00f6r driva p\\u00e5 fr\\u00e5gan p\\u00e5 ett mer aktivt s\\u00e4tt f\\u00f6r att \\u00e5tg\\u00e4rda situationen och undvika att personer vistas illegalt i Sverige.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"party\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"independent\",\n          \"S\",\n          \"MP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"titel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14197,\n        \"samples\": [\n          \"V\\u00e4rdet av s\\u00e4llskapsdjur i \\u00e4ldreomsorgen och kriminalv\\u00e5rden\",\n          \"St\\u00e4rkt sjukf\\u00f6rs\\u00e4kring m.m.\",\n          \"Mer l\\u00f6nsamt att ha arbetat \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtitel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2429,\n        \"samples\": [\n          \"av Niklas Karlsson och Elin Gustafsson (b\\u00e5da S)\",\n          \"av Jessika Roswall och Marta Obminska (b\\u00e5da M)\",\n          \"av Lennart Axelsson m.fl. (S)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-820fa972-444c-4293-a15b-7267a05aa988\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dok_id</th>\n",
              "      <th>text</th>\n",
              "      <th>party</th>\n",
              "      <th>label</th>\n",
              "      <th>titel</th>\n",
              "      <th>subtitel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14824</th>\n",
              "      <td>H9023140</td>\n",
              "      <td>LSS (lagen om st√∂d och service till vissa funk...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Statligt √∂vertagande av LSS</td>\n",
              "      <td>av Ann-Sofie Lifvenhage (M)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>H502826</td>\n",
              "      <td>Arbete √•t alla √§r grunden f√∂r v√§lf√§rdssamh√§lle...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Statliga insatser f√∂r ett aktivt n√§ringsliv</td>\n",
              "      <td>av Pia Nilsson m.fl. (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7832</th>\n",
              "      <td>H8022446</td>\n",
              "      <td>I Sverige finns cirka 30 science parks med oli...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>L√•ngsiktiga f√∂ruts√§ttningar f√∂r Science Parks</td>\n",
              "      <td>av Teresa Carvalho (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>H602991</td>\n",
              "      <td>Riksv√§g 53 sammanbinder Eskilstuna och Nyk√∂pin...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Bygg ut riksv√§g 53 mellan Eskilstuna och Nyk√∂ping</td>\n",
              "      <td>av Erik Bengtzboe (M)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16836</th>\n",
              "      <td>H6021071</td>\n",
              "      <td>Sedan 1967 ockuperar Israel √∂stra Jerusalem oc...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>M√§rk varor fr√•n ockuperade omr√•den</td>\n",
              "      <td>av Magnus Manhammar (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17041</th>\n",
              "      <td>H702929</td>\n",
              "      <td>En god mun- och tandh√§lsa √§r viktigt f√∂r livsk...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>St√∂d till tandh√§lsa</td>\n",
              "      <td>av Patrik Engstr√∂m m.fl. (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3812</th>\n",
              "      <td>H602748</td>\n",
              "      <td>M√•nga konsumenter √§r idag intresserade av vari...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Obligatorisk ursprungsm√§rkning av k√∂tt p√• rest...</td>\n",
              "      <td>av Johan L√∂fstrand m.fl. (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19736</th>\n",
              "      <td>H602992</td>\n",
              "      <td>Varje √•r genomf√∂rs √∂ver 700 organdonationer i ...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Inf√∂r en anm√§lan till donationsregistret via d...</td>\n",
              "      <td>av Erik Bengtzboe (M)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18770</th>\n",
              "      <td>H6022297</td>\n",
              "      <td>Sammanfattning. Kampen f√∂r de m√§nskliga r√§ttig...</td>\n",
              "      <td>MP</td>\n",
              "      <td>2</td>\n",
              "      <td>Nya reformer f√∂r hbtq-personers r√§ttigheter</td>\n",
              "      <td>av √Ösa Lindhagen m.fl. (MP)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13932</th>\n",
              "      <td>H4022525</td>\n",
              "      <td>Idag finns det en stor m√§ngd olika system f√∂r ...</td>\n",
              "      <td>SD</td>\n",
              "      <td>7</td>\n",
              "      <td>Nationellt journalsystem f√∂r en b√§ttre sjukv√•rd</td>\n",
              "      <td>av Markus Wiechel och Jennie √Öfeldt (b√•da SD)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19858 rows √ó 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-820fa972-444c-4293-a15b-7267a05aa988')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-820fa972-444c-4293-a15b-7267a05aa988 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-820fa972-444c-4293-a15b-7267a05aa988');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b965f3d6-2c25-43ec-8808-e5e2e69b5302\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b965f3d6-2c25-43ec-8808-e5e2e69b5302')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b965f3d6-2c25-43ec-8808-e5e2e69b5302 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         dok_id                                               text party  \\\n",
              "14824  H9023140  LSS (lagen om st√∂d och service till vissa funk...     M   \n",
              "4749    H502826  Arbete √•t alla √§r grunden f√∂r v√§lf√§rdssamh√§lle...     S   \n",
              "7832   H8022446  I Sverige finns cirka 30 science parks med oli...     S   \n",
              "337     H602991  Riksv√§g 53 sammanbinder Eskilstuna och Nyk√∂pin...     M   \n",
              "16836  H6021071  Sedan 1967 ockuperar Israel √∂stra Jerusalem oc...     S   \n",
              "...         ...                                                ...   ...   \n",
              "17041   H702929  En god mun- och tandh√§lsa √§r viktigt f√∂r livsk...     S   \n",
              "3812    H602748  M√•nga konsumenter √§r idag intresserade av vari...     S   \n",
              "19736   H602992  Varje √•r genomf√∂rs √∂ver 700 organdonationer i ...     M   \n",
              "18770  H6022297  Sammanfattning. Kampen f√∂r de m√§nskliga r√§ttig...    MP   \n",
              "13932  H4022525  Idag finns det en stor m√§ngd olika system f√∂r ...    SD   \n",
              "\n",
              "       label                                              titel  \\\n",
              "14824      5                        Statligt √∂vertagande av LSS   \n",
              "4749       1        Statliga insatser f√∂r ett aktivt n√§ringsliv   \n",
              "7832       1      L√•ngsiktiga f√∂ruts√§ttningar f√∂r Science Parks   \n",
              "337        5  Bygg ut riksv√§g 53 mellan Eskilstuna och Nyk√∂ping   \n",
              "16836      1                 M√§rk varor fr√•n ockuperade omr√•den   \n",
              "...      ...                                                ...   \n",
              "17041      1                                St√∂d till tandh√§lsa   \n",
              "3812       1  Obligatorisk ursprungsm√§rkning av k√∂tt p√• rest...   \n",
              "19736      5  Inf√∂r en anm√§lan till donationsregistret via d...   \n",
              "18770      2        Nya reformer f√∂r hbtq-personers r√§ttigheter   \n",
              "13932      7    Nationellt journalsystem f√∂r en b√§ttre sjukv√•rd   \n",
              "\n",
              "                                            subtitel  \n",
              "14824                    av Ann-Sofie Lifvenhage (M)  \n",
              "4749                        av Pia Nilsson m.fl. (S)  \n",
              "7832                          av Teresa Carvalho (S)  \n",
              "337                            av Erik Bengtzboe (M)  \n",
              "16836                        av Magnus Manhammar (S)  \n",
              "...                                              ...  \n",
              "17041                   av Patrik Engstr√∂m m.fl. (S)  \n",
              "3812                    av Johan L√∂fstrand m.fl. (S)  \n",
              "19736                          av Erik Bengtzboe (M)  \n",
              "18770                    av √Ösa Lindhagen m.fl. (MP)  \n",
              "13932  av Markus Wiechel och Jennie √Öfeldt (b√•da SD)  \n",
              "\n",
              "[19858 rows x 6 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df[\"datum\"] >= \"2018-10-01\"].reset_index(drop=True)\n",
        "df = df[df[\"single_party_authors\"] == True].reset_index(drop=True)\n",
        "df = df[df[\"subtyp\"] == \"Enskild motion\"] # Filter to keep only enskilda motioner\n",
        "label_mapping = {\n",
        "    0: \"V\",\n",
        "    1: \"S\",\n",
        "    2: \"MP\",\n",
        "    3: \"C\",\n",
        "    4: \"L\",\n",
        "    5: \"M\",\n",
        "    6: \"KD\",\n",
        "    7: \"SD\",\n",
        "    8: \"independent\",\n",
        "}\n",
        "label_mapping = {v: k for k, v in label_mapping.items()} # Reverse key/value\n",
        "df[\"label\"] = df[\"party\"].map(label_mapping)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df_train = df.sample(frac=0.85, random_state=5)\n",
        "df_valid = df.drop(df_train.index)\n",
        "\n",
        "df_train[[\"dok_id\", \"text\", \"party\", \"label\", \"titel\", \"subtitel\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRPYNOkKVYAe"
      },
      "source": [
        "### Creating a Pytorch Dataset\n",
        "\n",
        "Pytorch recommends separating your dataset code from your modeling code. They provide two \"data primitives\" to help the user do this: the [`Dataset` class and the `DataLoader`](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders).\n",
        "\n",
        "* The `Dataset` is a way of defining how to fetch and sample our dataset's variables and labels one by one.\n",
        "* The `DataLoader` is an abstraction that parallelizes the loading of samples from your `Dataset`, ensuring samples are continuously fetched in advance in separate processes, and passed to your model (e.g. if running on a GPU) without it having to pause and wait for the CPU to finish loading a new batch/sample each iteration.\n",
        "\n",
        "We start with writing a `Dataset` class for our setting. Every dataset class should *always* have the methods `__init__`, `__len__` and `__getitem__`. Their purpose is briefly explained in the comments of the example custom Dataset class implementation below, but you may also read about them in Pytorch's [guide on Datasets and DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#init).\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, my_texts, my_labels):\n",
        "        # Instance attributes that are shared and can be used in other methods\n",
        "        # of the class by writing self.attribute_name .\n",
        "        # Only run once, when the Dataset is instantiated.\n",
        "        self.my_texts = my_texts\n",
        "        self.my_labels = my_labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"KBLab/bert-base-swedish-cased\")\n",
        "\n",
        "    def __len__(self):\n",
        "        # A way of telling the class how many observations there are in\n",
        "        # your dataset. So that it knows the range of indices it can sample.\n",
        "        return len(self.my_texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Where we load and return a sample. __getitem__ is called whenever\n",
        "        # we use indexing on our dataset, e.g. mydataset[13], mydataset[0], etc\n",
        "        # \"index\" changes each iteration.\n",
        "        text_selected_obs = self.my_texts[index]\n",
        "        label_selected_obs = self.my_labels[index]\n",
        "\n",
        "        # Tokenize the text (can be done outside Dataset too).\n",
        "        # Pads to the model's maximum allowed sequence length if shorter.\n",
        "        tokenized_text = self.tokenizer(\n",
        "            text_selected_obs, padding=\"max_length\", truncation=True, return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # tokenized_text is a dictionary, so we squeeze in the label\n",
        "        # as an entry there as well, and just return everything as a\n",
        "        # single object.\n",
        "        tokenized_text[\"label\"] = torch.tensor(label_selected_obs)\n",
        "\n",
        "        return tokenized_text\n",
        "\n",
        "```\n",
        "\n",
        "Let's create our own Dataset class for the parliamentary motions below. We'll name it `MotionerDataset`, and make it simple for ourselves by passing our entire dataframe as input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qmqTeuaAMDxS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "class MotionerDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"KBLab/bert-base-swedish-cased\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        df_row = self.df.iloc[index]\n",
        "\n",
        "        label = df_row[\"label\"]\n",
        "        text = df_row[\"text\"]\n",
        "\n",
        "        # padding=\"max_length\" pads to the models maximum allowed length.\n",
        "        # Only do this if you expect most texts to be as long or longer than\n",
        "        # the maximum sequence length of the model (512 tokens in this case).\n",
        "        # We truncate if the sequence is too long.\n",
        "        tokenized_text = self.tokenizer(\n",
        "            text, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        label = torch.tensor(label)\n",
        "        tokenized_text[\"label\"] = label\n",
        "\n",
        "        return tokenized_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIPajP6bk1rP"
      },
      "source": [
        "Let's instantiate our dataset and see what it returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnY3z3WlVSaG",
        "outputId": "9527472d-5c57-48c1-e5e9-a878d74d70ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2, 44885,   177,  3661,   100,  1839,    36,  3239,    76,  1779,\n",
              "         39448, 28079,   171,  4374,   408,    48, 13407,    31, 17009,    68,\n",
              "         10379,  1251,  3156,    76,   137,   875,   635,     7,   982, 16813,\n",
              "             5,    65,  3661,   108,   137,  8147,  9689,  1276, 11098,     7,\n",
              "          2819,   845,    48, 46875, 30307,     9,    36,  6198,    43, 44885,\n",
              "         10397,  1382,   594,   829,  5246,    68,   137, 20968,   692,     7,\n",
              "          1478,    54, 36917,    31,   137, 11397,    36,  2910,  2335,   256,\n",
              "           440,   326,   331,  2477,    48,  5579,    36,  8545,    36,   256,\n",
              "          3661,   108,   369,  3418,    43,  1427,    66, 25894,  2373,     7,\n",
              "         47405, 25327,    54,   621,  1905,   802,  4352,    43,   137,  8147,\n",
              "         10379,  2477,    76, 13047,    19, 32776,    36,  7315,    31,  3508,\n",
              "             7,  2861,   403, 49397,  2701,    43,    97,   292,    65,  7394,\n",
              "         25327,    67,   346,    54,   137, 19042,  1494,  5047,   203,     7,\n",
              "           848,   137, 14189,  5902,  1494,    36,    59,  1396,    67,  3689,\n",
              "         20257,    36,  6121,   397,   127, 20257,    31, 18394,   594,   829,\n",
              "         12560, 46030,     7,     3,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'label': tensor(5)}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = MotionerDataset(df=df_train)\n",
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xnEkojAqYMi"
      },
      "source": [
        "What do the different dictionary keys mean? And why are there lots of zeroes at the end of our `input_ids`?\n",
        "\n",
        "* `input_ids`: Your tokenized text mapped to integers. The model expects the input as integers, so that it can select the correct row from the vocabulary token embedding matrix. These vectors are what is the actual input to the model. And every single row of the vocabulary embedding matrix maps to a certain token (via the input_id integer of the token).\n",
        "* `token_type_ids`: This is a way of keeping track of the indices of each sequence if we pass multiple texts as a single observation. This exists for BERT mainly because BERT has the pretraining task of `next_sentence_prediction` (two texts are passed as a single sequence), and because sometimes multiple shorter sequences are stacked and passed as one to fill up the maximum sequence length of the model. This is done in order not to waste compute by needlessly padding with 0s. In our case, we only put one text in the input sequence and thus don't need the `token_type_ids` to be able to separate them. We can in fact specify `return_token_type_ids=False` in the tokenizer to let it know that it shouldn't return them.\n",
        "* `attention_mask`: What tokens should the model ignore when computing attentions and losses? We want to ignore `[PAD]` tokens that sometimes need to be added at the end of a sequence to ensure all inputs in a given batch are of the same length/dimensions when passed to the model.\n",
        "* `label`: This is something we ourselves inserted into the dictionary in our `MotionerDataset` before returning it. We will need it later when computing the loss.\n",
        "\n",
        "We can check which tokens the integer `input_ids` map to by using `tokenizer.convert_ids_to_tokens()`. Note that the tokenizer split some words such as \"skyddssk√§l\" into \"skydds\" and \"##sk√§l\". This is made by the tokenizer to reduce the vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8RyNfe-yuMCL"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"KBLab/bert-base-swedish-cased\")\n",
        "input_ids = train_dataset[0][\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f06yM_MkuyVj",
        "outputId": "51a2fd53-986c-43c2-d5b9-1429cab2c8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'LSS', '(', 'lagen', 'om', 'st√∂d', 'och', 'service', 'till', 'vissa', 'funktionsh', '##indrade', ')', 'l√§mnar', 'mycket', 'att', '√∂nska', 'i', 'synen', 'p√•', 'm√§nniskors', 'lika', 'm√∂jligheter', 'till', 'ett', 'rikt', 'liv', '.', 'Efter', '√∂versyn', '##en', 'av', 'lagen', 'har', 'ett', 'flertal', 'brister', 'blivit', 'tydliga', '.', 'Bland', 'annat', 'att', 'bist√•nds', '##bed√∂mning', '##ar', 'och', 'kostnader', 'f√∂r', 'LSS', 'varierar', 'stort', 'mellan', 'olika', 'kommuner', 'p√•', 'ett', 'anm√§rkningsv√§rt', 's√§tt', '.', 'Detta', '√§r', 'oacceptabelt', 'i', 'ett', 'modernt', 'och', '√∂ppet', 'samh√§lle', 'd√§r', 'alla', 'ska', 'ha', 'm√∂jlighet', 'att', 'delta', 'och', 'bidra', 'och', 'd√§r', 'lagen', 'har', 'stor', 'betydelse', 'f√∂r', 'personer', 'med', 'funktionsned', '##s√§ttning', '.', 'Personlig', 'assistans', '√§r', 'm√•nga', 'g√•nger', 'helt', 'avg√∂rande', 'f√∂r', 'ett', 'flertal', 'm√§nniskors', 'm√∂jlighet', 'till', 'sj√§lvst√§ndighet', ',', 'livskvalitet', 'och', 'inflytande', 'i', 'samh√§llet', '.', 'D√§rf√∂r', 'b√∂r', 'huvudmanna', '##skapet', 'f√∂r', 'den', 'del', 'av', 'personlig', 'assistans', 'som', 'nu', '√§r', 'ett', 'kommunalt', 'ansvar', 'ses', '√∂ver', '.', 'Med', 'ett', 'statligt', 'ekonomiskt', 'ansvar', 'och', 'en', 'peng', 'som', 'f√∂ljer', 'individen', 'och', 'beslutet', 'kommer', 'inte', 'individen', 'i', 'kl√§m', 'mellan', 'olika', 'bostads', '##kommuner', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.convert_ids_to_tokens(input_ids[0])) # What tokens do the integer ids map to?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PTfFwY8waL5"
      },
      "source": [
        "### Using a DataLoader to load batches\n",
        "\n",
        "Python is limited in terms of using multiple threads in the same process. A `DataLoader` object abstracts away the creation of multiple processes via `multiprocessing`, where each process independently loads batches of data. It ensures several batches are fetched in advance so that our main process doesn't have to pause and wait for a batch to be processed by the `MotionerDataset` before being able to proceed to pass it to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G-R3YvAazcQF"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "train_dataset = MotionerDataset(df=df_train)\n",
        "valid_dataset = MotionerDataset(df=df_valid)\n",
        "\n",
        "# Colab free tier only has 2 CPUs\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcPkPsMnzyNA"
      },
      "source": [
        "### Example output of our DataLoader\n",
        "\n",
        "Dataloaders are [iterables](https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Iterables.html#Iterables), meaning we can iterate over them with `for` loops. If we want to inspect a batch manually without explicit looping, we need to use `iter()` and `next()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4flN4gP0uJW",
        "outputId": "83a15618-691c-4282-ae1f-1988c01da99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions of the batch: torch.Size([16, 1, 512])\n",
            "Labels: tensor([7, 5, 5, 7, 5, 5, 1, 5, 5, 7, 3, 5, 3, 7, 3, 5])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[    2,   285, 12966,  ...,     0,     0,     0]],\n",
              "\n",
              "        [[    2,  4199,    97,  ...,    19,   413,     3]],\n",
              "\n",
              "        [[    2,   285,    65,  ...,     0,     0,     0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[    2, 11024,   423,  ...,     0,     0,     0]],\n",
              "\n",
              "        [[    2,   160,    54,  ...,   198,   127,     3]],\n",
              "\n",
              "        [[    2, 18745, 37812,  ...,     0,     0,     0]]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(f\"Dimensions of the batch: {batch['input_ids'].size()}\") # 16 obs of dim 1x512\n",
        "print(f\"Labels: {batch['label']}\")\n",
        "batch[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_Yr3LSl5lh4"
      },
      "source": [
        "## Setting up the Swedish BERT model for classification\n",
        "\n",
        "Let's load KB-BERT from the `transformers` library. We will be loading it for the specific purpose of performing document classification. At Huggingface, models with a classification head (a dense linear layer on top of the base transformer) are all named `XForSequenceClassification`, where `X` is the specific model implementation. In our case that's the BERT.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtDMfQOK53Nj",
        "outputId": "e9050369-28a1-4961-e92b-fba5fdebdb72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "# Note that we define the number of categories with `num_labels`.\n",
        "model = BertForSequenceClassification.from_pretrained(\"KBLab/bert-base-swedish-cased\", num_labels=9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9hSr3YWBHka"
      },
      "source": [
        "We can look at the model and can identify the transformer layers. Just as in the original BERT we have 12 Transformer layers (called `BertLayer`) with self-attention (`BertSelfAttention`), here with dropout. Note that we can see the Q(uery), K(ey), and V(alue) parameters of the transformer layers. In the `BertSelfOutput` we can see the layer normalization of the output.\n",
        "\n",
        "The `BertIntermediate` part contain the feed-forward neural network och the transformer, here with a Gaussian Error Linear unit (GELu) activation function. We can also see the input (word) embedding layer with a vocabulary of size 50325 different word types, position embeddings, a layer normalization layer and dropout. The `BertPooler` layer is the classification head used for text classification with the BERT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpPOTXoFBGag",
        "outputId": "fedc7adc-db6e-4399-a0d1-8f693184f920"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50325, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qvk1LkvjAI6"
      },
      "source": [
        "Next we setup the use of a Graphical Processing Unit to speed up the training. This is strictly not nessecary, but make the training faster. We also check that the model is in training model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuQ_RrO4A1aq",
        "outputId": "8426a3f2-ee48-404c-b5a1-db7e3311512b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We use: cuda\n",
            "The model is in training mode:  True\n"
          ]
        }
      ],
      "source": [
        "# We can make use of GPU if the if you have activated GPU in Colab\n",
        "# Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"We use:\", device)\n",
        "model.to(device) # Should the model run on CPU or GPU?\n",
        "model.train() # In train mode dropout is active, in eval mode dropout is inactivated\n",
        "# Boolean showing whether the model is in train mode or in eval model.\n",
        "print(\"The model is in training mode: \", model.training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_7HZDAoBPhk"
      },
      "source": [
        "### Optimizer, loss function and learning rate scheduler\n",
        "\n",
        "Next, we will be loading an optimizer, a loss function (cross entropy loss), and a learning rate scheduler that will vary the learning rate throughout the training process.\n",
        "\n",
        "* Optimizer: AdamW.\n",
        "* Loss: Cross-entropy loss\n",
        "* Learning rate scheduler: Sets a schedule for how the base learning rate should change throughout the training (rather than keeping a fixed learning rate throughout).\n",
        "\n",
        "> \"Adam can substantially benefit from a scheduled learning rate multiplier. The fact that Adam is an adaptive gradient algorithm and as such adapts the learning rate for each parameter does not rule out the possibility to substantially improve its performance by using a global learning rate multiplier, scheduled, e.g., by cosine annealing\" ([Loshcilov & Hutter, 2019](https://arxiv.org/abs/1711.05101))\n",
        "\n",
        "For our learning rate scheduler, we'll use the Kaggle-\"trendy\" [OneCycleLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html#onecyclelr).\n",
        "\n",
        "Optimal learning rates are dataset and model dependent. If you set it manually, a normal process to figure out a reasonable rate is to train for a few minutes while keeping track of the loss. Then restart the training changing the loss by an order of magnitude or more, while comparing how quickly the loss drops. You may also try \"hyperparameter optimization\" tools that explores the optimal paramters for you. Though, these tools can tend to be fairly overkill for simple finetuning problems such as this one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nAe6T_trEZ4W"
      },
      "outputs": [],
      "source": [
        "# The total number of epochs\n",
        "nr_epochs=4\n",
        "\n",
        "# The optimizer we are going to use\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# The loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# The learning rate scheduler\n",
        "learning_rate_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-5,\n",
        "    epochs=nr_epochs,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVSDpuJkEy8i"
      },
      "source": [
        "A learning rate scheduler change the learning rate over the training time. In fact, we can step through the scheduler and extract its learning rate values for each iteration even without training the model.  The total number of steps that the scheduler will generate learning rates for will be `nr_epochs * len(train_loader)`.\n",
        "\n",
        "Let's loop through all these values and extract the learning rate for each step of the scheduler. We can plot the results with `matplotlib` as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "A5Fe2FeCAKaN",
        "outputId": "26c2ff09-1e77-462c-d5ca-7c648763bd9d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "plt.rcParams['figure.figsize'] = [12, 6]\n",
        "\n",
        "iter = []\n",
        "learning_rates = []\n",
        "for i in range(nr_epochs * len(train_loader)):\n",
        "    optimizer.step()\n",
        "    learning_rates.append(learning_rate_scheduler.get_last_lr())\n",
        "    iter.append(i)\n",
        "    learning_rate_scheduler.step()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(iter, learning_rates)\n",
        "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-JbXNYHpv7G"
      },
      "source": [
        "## Training/finetuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPPCRoBJny9s"
      },
      "source": [
        "Currently all parameters in the BERT model going to be trained. The `boolean` `param.requires_grad` indicates if the weight should be trained (`True`) or if it is freezed (`False`). Hence we can list the parameters to train as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjmfL4kcnzax",
        "outputId": "61a5fcc7-c7f4-496a-9d8e-649c1f89eabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ],
      "source": [
        "# List parameters to train\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8n0Z5dron_w"
      },
      "source": [
        "As a first step we will only train the classification head, that is the bert.pooler layer and the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGUblDYKpJsa",
        "outputId": "efa33326-4183-4684-a5da-7855784fa090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ],
      "source": [
        "# We now just set some parameters to be trained\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.bert.pooler.dense.weight.requires_grad = True\n",
        "model.bert.pooler.dense.bias.requires_grad = True\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True\n",
        "\n",
        "# List parameters to train\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6wa2R5b5JgF"
      },
      "source": [
        "\n",
        "Now to the actual training of the model. Our approach will be to write a standard Pytorch training loop, where we iterate over the epochs and batches with `for` loops. The general structure for such a training loop is as follows:\n",
        "\n",
        "```python\n",
        "nr_epochs = 4\n",
        "\n",
        "for epoch in range(nr_epochs):\n",
        "  for i, batch in enumerate(train_loader):\n",
        "    # We set the gradients to zero\n",
        "    optim.zero_grad()\n",
        "\n",
        "    # Extract the input_ids, attention_mask and labels.\n",
        "    # Make sure they are on the right device before being passed to model.\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(device)\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "\n",
        "    # Compute the loss\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    loss = loss_function(outputs[\"logits\"], labels)\n",
        "\n",
        "    loss.backward() # Gradient update step, backward pass\n",
        "    optim.step() # Optimizer update step\n",
        "    scheduler.step() # Scheduler update step\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KixOPzNiSZ1"
      },
      "source": [
        "Since we stepped through our optimizer and scheduler above, we need to reinstantiate them once again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rBlDU0VHH5i0"
      },
      "outputs": [],
      "source": [
        "# The total number of epochs\n",
        "nr_epochs=1\n",
        "\n",
        "# The optimizer we are going to use\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# The loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# The learning rate scheduler\n",
        "learning_rate_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-5,\n",
        "    epochs=nr_epochs,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWBSt4RgNSYD"
      },
      "source": [
        "Why would we prefer writing our own training loop as opposed to just using some framework providing cushy high level abstractions? As we'll see soon, the benefit is mainly that you have the freedom to customize, adapt and debug your code very easily and freely.\n",
        "\n",
        "* **Customization**: You don't need to understand the ins and outs of a framework, nor inspect its source code to implement, adapt and change things.\n",
        "* **Debugging**: Every parameter, every loss, every optimizer state, every scheduler state, every input and every output is available and easily inspectable for you. These things are generally hidden away from you when using higher level frameworks.\n",
        "\n",
        "For our actual training loop, we will add a few things.\n",
        "\n",
        "1. At certain intervals of iterations we would like to print our average loss during that interval.\n",
        "2. Every epoch we would like to print our accuracy, a confusion matrix, and some other useful metrics.\n",
        "\n",
        "In order to be fully transparent, I should state that in a typical work flow,  generally the training loop is developed first without having prediction code in place. Generally the process will include training the model for a while without doing evaluations and predictions (only tracking loss). At this stage is where the partly trained -- and unfinished -- model is used to write a proper prediction function with evaluation measures. This step is generally easier and less error prone to code once the model starts making predictions that are somewhat sensible.\n",
        "\n",
        "In this tutorial I will provide a prediction function immediately, but keep in mind that the figuring out of how to do basic prediction generally comes *after* having a model that no longer outputs random jibberish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NmjuiuDjUKGq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def predict(model, df_valid):\n",
        "    probs_list = []\n",
        "\n",
        "    # Ensure model is in eval mode before predicting (this ignores dropout layers)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(valid_loader)):\n",
        "            # .squeeze(dim=1) changes dims [16, 1, 512] ---> [16, 512]\n",
        "            input_ids = batch[\"input_ids\"].squeeze(dim=1).to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].squeeze(dim=1).to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            probs_list += torch.nn.functional.softmax(outputs[\"logits\"], dim=1)\n",
        "\n",
        "        preds = [torch.argmax(probs, dim=0).to(\"cpu\") for probs in probs_list]\n",
        "        df_valid[\"preds\"] = [int(pred) for pred in preds]\n",
        "        df_valid[\"probs\"] = [probs.to(\"cpu\").tolist() for probs in probs_list]\n",
        "\n",
        "    return df_valid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnks63axURqm"
      },
      "source": [
        "### Train the classification head (takes approx 8 minutes)\n",
        "\n",
        "One devious thing we have to look out for is that models expect input of a certain dimensionality. Sometimes the output of our dataset/dataloader might not conform to these expectations. In our case the dimensionality of a batch of `input_ids` comes out as $16\\times1\\times512$. We can think of it as $16$ observations of $1\\times512$ matrices. However, the row dimension $1$ of those matrices is redundant here. We might as well think of it as $16$ observations of $512$-length vectors. The model in fact expects a dimensionality of `(batch_size, input_length)` for each batch.\n",
        "\n",
        "A common operation for making this redundant $1$-dimensions disappear in Pytorch is the `.squeeze()` operation. Conversely, if we want to insert one of these dimensions (because a model for some reason expects it), we can use `.unsqueeze()`.\n",
        "\n",
        "In the code below you will see `batch[\"input_ids\"].to(device).squeeze(dim=1)`, where we transform `input_ids` from $16\\times1\\times512$ to $16\\times512$. The argument `dim` here refers to along which of the 3 axes `(batch_size, dummy_row, input_length)`: $16$, $1$ or $512$ that we want to perform the squeeze operation. The dimension axes start counting from $0$ (with $0$ being the `batch_size` dimension).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukTK8oX9Vv4q",
        "outputId": "2d76ca9f-84b8-466f-8e88-acfb081aa43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|‚ñç         | 50/1242 [00:24<09:22,  2.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 50, loss: 2.34566741, lr: [3.68416197944788e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|‚ñä         | 100/1242 [00:47<09:16,  2.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 100, loss: 2.21167184, lr: [9.11469217100445e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|‚ñà‚ñè        | 150/1242 [01:12<08:43,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 150, loss: 1.98781348, lr: [9.986861102616165e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|‚ñà‚ñå        | 200/1242 [01:36<08:15,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 200, loss: 1.80886124, lr: [9.886967048742394e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|‚ñà‚ñà        | 250/1242 [01:59<07:50,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 250, loss: 1.77233727, lr: [9.690726842778463e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|‚ñà‚ñà‚ñç       | 300/1242 [02:23<07:32,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 300, loss: 1.69483094, lr: [9.402009360024524e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|‚ñà‚ñà‚ñä       | 350/1242 [02:47<07:09,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 350, loss: 1.68977155, lr: [9.026506665122783e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|‚ñà‚ñà‚ñà‚ñè      | 400/1242 [03:11<06:38,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 400, loss: 1.63217745, lr: [8.571621793013548e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|‚ñà‚ñà‚ñà‚ñå      | 450/1242 [03:35<06:19,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 450, loss: 1.67746729, lr: [8.046322798114971e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|‚ñà‚ñà‚ñà‚ñà      | 500/1242 [03:59<05:58,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 500, loss: 1.67131691, lr: [7.460965949146668e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 550/1242 [04:22<05:30,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 550, loss: 1.64564170, lr: [6.827091555310928e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 600/1242 [04:46<05:04,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 600, loss: 1.66208353, lr: [6.157196449117995e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 650/1242 [05:10<04:43,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 650, loss: 1.64475541, lr: [5.464487611356073e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 700/1242 [05:34<04:16,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 700, loss: 1.60611450, lr: [4.762621795489348e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 750/1242 [05:58<03:54,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 750, loss: 1.62527034, lr: [4.065436284788526e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 800/1242 [06:22<03:30,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 800, loss: 1.64495043, lr: [3.386676090316556e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 850/1242 [06:46<03:07,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 850, loss: 1.62009184, lr: [2.739722968060787e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 900/1242 [07:09<02:42,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 900, loss: 1.61791306, lr: [2.137331597638236e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 950/1242 [07:33<02:19,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 950, loss: 1.65114936, lr: [1.5913781238103823e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1000/1242 [07:57<01:55,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 1000, loss: 1.69761619, lr: [1.1126260183109927e-06]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1050/1242 [08:21<01:31,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 1050, loss: 1.63536525, lr: [7.105138780206713e-07]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1100/1242 [08:45<01:07,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 1100, loss: 1.64228163, lr: [3.9296934304668565e-07]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1150/1242 [09:09<00:43,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 1150, loss: 1.53418437, lr: [1.6625280331281726e-07]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1200/1242 [09:33<00:19,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " iter: 1200, loss: 1.66075632, lr: [3.4833974983513385e-08]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1242/1242 [09:52<00:00,  2.10it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [01:40<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4115296803652968\n",
            "\u001b[94m Confusion Matrix: \u001b[0m \n",
            "preds   1     5   All\n",
            "label                \n",
            "0       0     1     1\n",
            "1      20   689   709\n",
            "2       1   130   131\n",
            "3       5   342   347\n",
            "4       6   139   145\n",
            "5       7  1422  1429\n",
            "6       2   187   189\n",
            "7       2   521   523\n",
            "8       0    30    30\n",
            "All    43  3461  3504\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           V       0.00      0.00      0.00         1\n",
            "           S       0.47      0.03      0.05       709\n",
            "          MP       0.00      0.00      0.00       131\n",
            "           C       0.00      0.00      0.00       347\n",
            "           L       0.00      0.00      0.00       145\n",
            "           M       0.41      1.00      0.58      1429\n",
            "          KD       0.00      0.00      0.00       189\n",
            "          SD       0.00      0.00      0.00       523\n",
            " independent       0.00      0.00      0.00        30\n",
            "\n",
            "    accuracy                           0.41      3504\n",
            "   macro avg       0.10      0.11      0.07      3504\n",
            "weighted avg       0.26      0.41      0.25      3504\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "loss_logger = []\n",
        "iter_before_print = 50 # Iterations before printing avg loss\n",
        "\n",
        "for epoch in range(nr_epochs):\n",
        "    print(f\"epoch: {epoch + 1} started\")\n",
        "    running_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # .squeeze(dim=1) changes dims [16, 1, 512] ---> [16, 512]\n",
        "        input_ids = batch[\"input_ids\"].squeeze(dim=1).to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].squeeze(dim=1).to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_function(outputs[\"logits\"], labels)\n",
        "\n",
        "        # Collect losses to print running avg, and later plotting\n",
        "        running_loss += loss.item()\n",
        "        if i % iter_before_print == (iter_before_print - 1):\n",
        "            print(\n",
        "                (\n",
        "                f\" iter: {i+1}, loss: {running_loss/iter_before_print:.8f}, \"\n",
        "                f\"lr: {learning_rate_scheduler.get_last_lr()}\"\n",
        "                )\n",
        "            )\n",
        "            loss_logger.append({\"iter\": i + 1,\n",
        "                                \"loss\": running_loss / iter_before_print})\n",
        "            running_loss = 0\n",
        "\n",
        "        # Updates of gradients and learning rate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        learning_rate_scheduler.step()\n",
        "\n",
        "    # Prediction and evaluation metrics\n",
        "    df_res = predict(model=model, df_valid=df_valid)\n",
        "    accuracy = sum(df_res[\"label\"] == df_res[\"preds\"]) / len(df_res)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(\n",
        "        (\n",
        "            f\"\\033[94m Confusion Matrix: \\033[0m \\n\" # Blue colored text\n",
        "            f\"{pd.crosstab(df_res['label'], df_res['preds'], margins=True)}\"\n",
        "        )\n",
        "    )\n",
        "    print(metrics.classification_report(y_true=df_res[\"label\"],\n",
        "                                        y_pred=df_res[\"preds\"],\n",
        "                                        labels=list(label_mapping.values()),\n",
        "                                        target_names=label_mapping.keys(),\n",
        "                                        zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqcNXlDS8_zm"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "How did the model perform on our evaluation dataset? It seems the model managed to to predict the correct party for roughly $46\\%$ of the parliamentary motions correctly. Although the data is unbalanced and the macro average indicate that we can improve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH4iVRGsaTzG",
        "outputId": "e4dd0888-e39a-4573-e7d0-1baaeb32a295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           V       0.00      0.00      0.00         1\n",
            "           S       0.47      0.03      0.05       709\n",
            "          MP       0.00      0.00      0.00       131\n",
            "           C       0.00      0.00      0.00       347\n",
            "           L       0.00      0.00      0.00       145\n",
            "           M       0.41      1.00      0.58      1429\n",
            "          KD       0.00      0.00      0.00       189\n",
            "          SD       0.00      0.00      0.00       523\n",
            " independent       0.00      0.00      0.00        30\n",
            "\n",
            "    accuracy                           0.41      3504\n",
            "   macro avg       0.10      0.11      0.07      3504\n",
            "weighted avg       0.26      0.41      0.25      3504\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    metrics.classification_report(\n",
        "        df_res[\"label\"],\n",
        "        df_res[\"preds\"],\n",
        "        labels=list(label_mapping.values()),\n",
        "        target_names=label_mapping.keys(),\n",
        "        zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiUpch6hVfUq"
      },
      "source": [
        "### Test our model on recent parliamentary motions\n",
        "\n",
        "We can test our model on texts from recently submitted parliamentary motions, which are neither part of the train nor the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsOqhp7LV110",
        "outputId": "da2e818e-be3b-40ea-93cd-0fac974de998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0153, 0.2227, 0.0406, 0.0932, 0.0447, 0.3779, 0.0672, 0.1184, 0.0201]],\n",
            "       device='cuda:0')\n",
            "tensor(5)\n"
          ]
        }
      ],
      "source": [
        "# Parliamentary motion from Milj√∂partiet: https://www.riksdagen.se/sv/dokument-lagar/dokument/motion/stoppa-handeln-med-utrotningshotade-djur_HA022280\n",
        "motions_text = \"\"\"\n",
        "Handeln med hotade arter √§r v√§rldens fj√§rde st√∂rsta illegala handel, och oms√§tter ofantliga summor som g√∂der kriminella n√§tverk.\n",
        "Forskare har l√§nge varnat om att allt fler virus riskerar att spridas fr√•n djur till m√§nniskor.\n",
        "Utbrottet av Coronaviruset Covid-19 har √•terigen satt str√•lkastarljuset p√• kopplingen mellan djurmarknader och sjukdomar.\n",
        "En anledning till att risken f√∂r virusspridning √∂kar p√• marknaderna √§r att det √§r ohygieniska f√∂rh√•llanden med en stor blandning av olika djurarter, ofta stressade ‚Äì som aldrig skulle tr√§ffas naturligt i det vilda. Olika virus kan d√• hoppa fr√•n en djurart till en annan och sedan vidare till m√§nniskan.\n",
        "P√• den internationella marknaden s√§ljs varje √•r flera miljoner vildf√•ngade f√•glar, tiotusentals apor och ett or√§kneligt antal andra djur och v√§xter¬†√•r p√• den internationella marknaden. Djuren s√§ljs som exotiska husdjur, eller s√• anv√§nds deras p√§lsar och skin inom kl√§dindustrin.\n",
        "Delar fr√•n skelett, horn och betar anv√§nds som ingredienser i naturmediciner och mat, till smycken och prydnadsf√∂rem√•l. Den stora efterfr√•gan p√• elfenben bidrar till allt f√∂r stor jakt p√• v√§rldens elefanter. √Ñven v√§rldens nosh√∂rningsarter hotas av tjuvjakt och illegal handel.\n",
        "\"\"\"\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = tokenizer(\n",
        "        motions_text, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(outputs[\"logits\"], dim=1)\n",
        "    preds = torch.argmax(probs).to(\"cpu\")\n",
        "\n",
        "print(probs)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUvDR5_mgNZ7"
      },
      "source": [
        "## Authors\n",
        "\n",
        "* Faton Rekathati (faton.rekathati@kb.se)\n",
        "* M√•ns Magnusson (mans.magnusson@statistik.uu.se)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hUvDR5_mgNZ7"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
