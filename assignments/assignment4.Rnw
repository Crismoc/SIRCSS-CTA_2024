\documentclass[11pt,a4paper,english]{article}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}

\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

% Normal latex T1-fonts
\usepackage[T1]{fontenc}

% Figures
\usepackage{graphicx}

 % AMS-stuff
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsbsy}

 % Misc
\usepackage{verbatim}
\usepackage{url}

\usepackage[round]{natbib}
\bibliographystyle{unsrtnat}

% Page size
\addtolength{\hoffset}{-1cm}
\addtolength{\textwidth}{2cm}
\addtolength{\voffset}{-1cm}
\addtolength{\textheight}{2cm}

% Paragraph
\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}

% Horizontal line
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% No page numbers
\pagestyle{empty}

% New commands:
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}

\begin{document}
%\SweaveOpts{concordance=TRUE}

\begin{titlepage}

\center
\textsc{\LARGE SIRCSS-CTA}\\[1.5cm] % Name of your university/college

\HRule \\[0.4cm]
{ \huge \bfseries Lab 4: Large Language Models}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]

\vfill

\end{titlepage}


% General Knitr options
% (this cannot be input since the file runs knitr before LaTeX)

<<echo=FALSE, eval=TRUE>>=
options(continue="  ", prompt="> ")
knitr::opts_chunk$set(size = "small")
@

\section{* Prompt engineering with ChatGPT}

You can choose to either do this task or the task above to get VG on this assignment.

\input{distinction_task.tex}

For this assignment, you need to have a user account at Open AI to generate an API token. See \href{https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key}{[this link]} for details on how to get an API token to use.

\textcolor{red}{\emph{Warning:}} Do not upload any files containing your API key to public repositories (Github, public google colab, etc.).

You also need to buy credits at Open AI. I think 1-2 dollars should be sufficient for this assignment.

As a second step you need to install the \texttt{ropenaiapi} R package. This can be done as follows:
<<eval=FALSE>>=
library(remotes)
remotes::install_github('MansMeg/ropenaiapi')
@
In the next step we set the API key as an environment variable with:
<<eval=FALSE>>=
library(ropenaiapi)
set_openai_api_key("[YOUR KEY GOES HERE]")
@

We can now call the API with the \texttt{openai\_chat} function.

<<eval=FALSE>>=
x <- openai_chat("Who is Gustav Vasa? Give a short answer.",
                 model = "gpt-3.5-turbo")
x
@

<<echo=FALSE,eval=TRUE>>=
cat("assistant:
Gustav Vasa was a Swedish king who led a successful rebellion
against Danish rule and became the founder of modern Sweden in
the 16th century.")
@

See the \texttt{ropenaiapi} documentation with ```?openai\_chat``` in R for further information on how to interact with the Open AI API.

\emph{Note!} If you get ```Error: You exceeded your current quota, please check your plan and billing details.``` that means that you don't have any credits to use for the calls. You then need to buy some credits from Open AI, 1-2 dollars should be sufficient for this task.


\subsection{Make ChatGPT hallucinate}

We are now going to understand how and when transformer-based decoder models 'hallucinate', i.e. when the models give factual incorrect information. See \cite[][, Section 7.1.2]{zhao2023survey} for an introduction and \cite{huang2023survey} for details on hallucinations in LLMs.

Now, create 3 different hallucinations with three different strategies (i.e. its not ok to use the same prompt for three incorrect generations) from the chatGPT models (you can choose which one you like). For each generated hallucination return:

\begin{enumerate}
\item The prompt and a the \texttt{seed} supplied to the API. You are free to both create hallucinations through a longer conversation and tuning parameters.
\item The response from the LLM.
\item Why the response is factually incorrect and weather it is an intrinsic or extrinsic hallucination.
\item Describe the strategy you use and the analysis why the hallucination happened.
\end{enumerate}

As a final step, when you have succeded to get the LLM to hallucinate, change the model to GPT-4 (include exact which model you use) and run the same prompt that you could get to hallucinate.

\begin{enumerate}
\item Return the response from GPT4 for each prompt.
\item Is the response still factually incorrect? If not, see if you can get at least one hallucination for GPT-4. If you don't succeed, just state that.
\end{enumerate}



\subsection{In-Context Learning for few-shot classification}

In-context learning is the idea to use large language models to complete tasks in a few-shot or zero-shot way. In this task we are going to try to classify political quotes in Swedish to weather they belong to the social democratic party manifesto or the conservative party (Moderaterna) manifesto.

\emph{Note!} This data is included in \texttt{uuml} version 0.4.0 and later.

<<eval=TRUE>>=
library(uuml)
data("pc_test")
data("pc_train")
@

Below is an example on how you can combine the data to a text string that can be combined to be used in a prompt. Note, you need to develop further on this.

<<eval=FALSE>>=
example_string <- paste0(pc_train$quote,
                         ": ",
                         pc_train$party, collapse = "\n\n")
cat(example_string)
@

See \cite[][, Section 8]{zhao2023survey} for details on how to best engineer prompts to solve the classification task.

Now use the techniques \cite[][, Section 8]{zhao2023survey} to generate as good prompts as possible to classify weather a quote is from the social democratic or the conservative manifesto.


\begin{enumerate}
\item Start with zero-shot learning, ie only prompt the LLM without any demonstrations. Test to classify the quotes in the test set.
\item Test how far you can get by using better prompt descriptions to classify the quotes. Try to get responses as classes from the model.
\item Now add demonstrations by adding examples from the training set. Does that improve the accuracy on the testset?
\item Try at least three different strategies from \cite[][, Section 8]{zhao2023survey} to improve the quality. Discuss your conclusions.
\end{enumerate}

\newpage


\bibliography{bibliography}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
